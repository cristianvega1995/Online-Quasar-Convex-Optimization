{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a231f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing folder 'Dataset1'...\n",
      "Datasets split and saved in 'Dataset1' folder successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download script\n",
    "# Necesary to Run the download script\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil  # For deleting the folder\n",
    "import scipy\n",
    "import torch\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the folder where you want to save the dataset\n",
    "dataset_folder = \"Dataset1\"\n",
    "\n",
    "# Check if the folder exists, and if so, delete it\n",
    "if os.path.exists(dataset_folder):\n",
    "    print(f\"Deleting existing folder '{dataset_folder}'...\")\n",
    "    shutil.rmtree(dataset_folder)\n",
    "\n",
    "# Create the folders for training, validation, and test datasets\n",
    "train_folder = os.path.join(dataset_folder, \"Train\")\n",
    "val_folder = os.path.join(dataset_folder, \"Validation\")\n",
    "test_folder = os.path.join(dataset_folder, \"Test\")\n",
    "\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Create subfolders for clean and noisy images\n",
    "train_clean_folder = os.path.join(train_folder, \"Groundtruth\")\n",
    "train_noisy_folder = os.path.join(train_folder, \"Degraded\")\n",
    "\n",
    "val_clean_folder = os.path.join(val_folder, \"Groundtruth\")\n",
    "val_noisy_folder = os.path.join(val_folder, \"Degraded\")\n",
    "\n",
    "test_clean_folder = os.path.join(test_folder, \"Groundtruth\")\n",
    "test_noisy_folder = os.path.join(test_folder, \"Degraded\")\n",
    "\n",
    "os.makedirs(train_clean_folder, exist_ok=True)\n",
    "os.makedirs(train_noisy_folder, exist_ok=True)\n",
    "\n",
    "os.makedirs(val_clean_folder, exist_ok=True)\n",
    "os.makedirs(val_noisy_folder, exist_ok=True)\n",
    "\n",
    "os.makedirs(test_clean_folder, exist_ok=True)\n",
    "os.makedirs(test_noisy_folder, exist_ok=True)\n",
    "\n",
    "# Load the MNIST dataset using TensorFlow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Smaller sets\n",
    "N_train_set = 2000\n",
    "N = train_images.shape[1]\n",
    "\n",
    "# Artificial blur\n",
    "sigma = 1\n",
    "\n",
    "# Since N is very small, we can implement the blurring operator as a matrix\n",
    "K_Mat = np.eye(N ** 2)\n",
    "for i in range(N ** 2):\n",
    "    figu = K_Mat[:, i].reshape(N, N)\n",
    "    K_Mat[:, i] = scipy.ndimage.gaussian_filter(figu, sigma).reshape(N ** 2)\n",
    "KtK_Mat = np.matmul(np.transpose(K_Mat), K_Mat)\n",
    "\n",
    "# Add noise\n",
    "noise_lev = 0.05\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_images, val_test_images, train_labels, val_test_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(val_test_images, val_test_labels, test_size=0.5, random_state=42)\n",
    "N_val_set = int(0.2 * N_train_set)\n",
    "N_test_set = int(0.2 * N_train_set)\n",
    "N_train_set = int(0.5 * N_train_set)\n",
    "train_images=train_images[0:N_train_set, :, :]\n",
    "test_images=train_images[0:N_test_set, :, :]\n",
    "val_images=train_images[0:N_val_set, :, :]\n",
    "\n",
    "# These are matrices of vectors\n",
    "test_noisy_images = np.matmul(test_images.reshape(-1, N ** 2), np.transpose(K_Mat)).reshape(-1, N, N) + noise_lev * np.random.randn(*test_images.shape)\n",
    "train_noisy_images = np.matmul(train_images.reshape(-1, N ** 2), np.transpose(K_Mat)).reshape(-1, N, N) + noise_lev * np.random.randn(*train_images.shape)\n",
    "val_noisy_images = np.matmul(val_images.reshape(-1, N ** 2), np.transpose(K_Mat)).reshape(-1, N, N) + noise_lev * np.random.randn(*val_images.shape)\n",
    "\n",
    "# Save each dataset in its respective folder\n",
    "def save_images_as_arrays(data, label, clean_folder, noisy_folder, prefix, set_type):\n",
    "    for i, (image_data, image_label) in enumerate(zip(data, label)):\n",
    "        clean_image_filename = os.path.join(clean_folder, f\"{prefix}_Gr_{set_type}_{i }.npy\")\n",
    "        noisy_image_filename = os.path.join(noisy_folder, f\"{prefix}_Dr_{set_type}_{i}.npy\")\n",
    "        np.save(clean_image_filename, image_data)\n",
    "        #np.save(clean_image_filename.replace(\".npy\", \"_label.npy\"), image_label)\n",
    "        np.save(noisy_image_filename, data[i])\n",
    "        #np.save(noisy_image_filename.replace(\".npy\", \"_label.npy\"), image_label)\n",
    "\n",
    "# Save training images and labels\n",
    "save_images_as_arrays(train_images, train_labels, train_clean_folder, train_noisy_folder, \"x\", \"tr\")\n",
    "\n",
    "# Save validation images and labels\n",
    "save_images_as_arrays(val_images, val_labels, val_clean_folder, val_noisy_folder, \"x\", \"va\")\n",
    "\n",
    "# Save testing images and labels\n",
    "save_images_as_arrays(test_images, test_labels, test_clean_folder, test_noisy_folder, \"x\", \"te\")\n",
    "\n",
    "print(\"Datasets split and saved in 'Dataset1' folder successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da32678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
